{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d114bb",
   "metadata": {},
   "source": [
    "# CosmoTree (Gtol)\n",
    "\n",
    "A single-notebook pipeline to render large weighted phylogenetic tree with Cosmograph. The notebook:\n",
    "- Parses Newick into a lightweight typed tree\n",
    "- Computes cumulative branch-length X and equal-spaced leaf Y\n",
    "- Lays out an orthogonal tree with elbows and non-overlapping stems\n",
    "- Renders via `cosmograph_widget.Cosmograph` using scalable per-kind sizes\n",
    "\n",
    "Performance rationale: Cosmograph handles tens of thousands of nodes interactively; matplotlib/similar packages are too slow for this scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3aa4be",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Iterable\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def _log(*args: object) -> None:\n",
    "    print(*args, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4769bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "# Geometry & appearance\n",
    "X_SCALE_PX: float = 140.0  # px per branch-length unit\n",
    "MIN_STEM_GAP_PX: float = 56.0  # min horizontal gap between adjacent vertical stems\n",
    "PARENT_STUB_PX: float = 20.0  # elbow stub length before vertical\n",
    "WEIGHTED_STUB_PX: float = 40.0  # minimal horizontal stub to weighted segment (set to 0 to preserve the ratio)\n",
    "LEAF_Y_STEP_PX: float = 400.0  # vertical spacing between consecutive leaves\n",
    "TIP_PAD_PX: float = 40.0  # extra space right of farthest leaf for markers\n",
    "\n",
    "# Per-kind point sizes (in pixels for direct strategy)\n",
    "SIZE_LEAF_MARKER: float = 20.0\n",
    "SIZE_INTERNAL: float = 6.0\n",
    "SIZE_BEND: float = 3.0\n",
    "SIZE_LEAF_REAL: float = 8.0\n",
    "\n",
    "# Global size scaling factor (applied before Cosmograph)\n",
    "NODE_SIZE_SCALE: float = 2.0\n",
    "\n",
    "# Colors\n",
    "COLOR_LEAF: str = \"#f5d76e\"  # yellow\n",
    "COLOR_INTERNAL: str = \"#8ab4f8\"  # light blue\n",
    "COLOR_BEND: str = \"#9aa0a6\"  # gray\n",
    "COLOR_LINK: str = \"#97A1A9\"  # gray\n",
    "LINK_WIDTH_PX: float = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58c68b",
   "metadata": {},
   "source": [
    "## Newick parsing\n",
    "\n",
    "We tokenize Newick with a small (not really) regex, then build a typed node map using a stack:\n",
    "- On `(` create an internal node and descend; on `)` assign pending attributes and ascend\n",
    "- Leaf tokens become nodes attached to current parent\n",
    "- `:length` applies to the last emitted node or is stored pending for the just-closed group\n",
    "- If multiple roots appear, we synthesize a single `root0`\n",
    "\n",
    "Complexity is linear in input length. Names and lengths are preserved; branch lengths < 0 are clamped later during layout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newick parsing — code\n",
    "\n",
    "@dataclass\n",
    "class TNode:\n",
    "    \"\"\"A tree node parsed from Newick.\n",
    "\n",
    "    Attributes:\n",
    "        id: Stable synthetic identifier.\n",
    "        name: Label (for leaves typically), may be empty.\n",
    "        parent: Parent node id or None for root.\n",
    "        blen: Branch length from parent to this node (non-negative real expected).\n",
    "        children: Child node ids in insertion order.\n",
    "    \"\"\"\n",
    "    id: str\n",
    "    name: str = \"\"\n",
    "    parent: Optional[str] = None\n",
    "    blen: float = 0.0\n",
    "    children: List[str] = field(default_factory=list)\n",
    "\n",
    "_TOKEN_RE = re.compile(r\"\\s*([(),;])\\s*|\\s*([^(),:;]+)\\s*|(\\s*:\\s*[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)\")  # help me\n",
    "\n",
    "\n",
    "def _tokenize(newick: str) -> Iterable[str]:\n",
    "    \"\"\"Yield tokens from Newick: parens, commas, semicolon, names, and ':len'.\"\"\"\n",
    "    i = 0\n",
    "    s = newick.strip()\n",
    "    while i < len(s):\n",
    "        m = _TOKEN_RE.match(s, i)\n",
    "        if not m:\n",
    "            if s[i].isspace():\n",
    "                i += 1\n",
    "                continue\n",
    "            raise ValueError(f\"[Newick] Unexpected token near: {s[i:i+20]!r}\")\n",
    "        tok = m.group(1) or m.group(2) or m.group(3)\n",
    "        if tok is not None:\n",
    "            yield tok.strip()\n",
    "        i = m.end()\n",
    "\n",
    "\n",
    "def parse_newick(newick: str) -> Dict[str, TNode]:\n",
    "    \"\"\"Parse Newick text into a node-id -> TNode map.\n",
    "\n",
    "    Rules:\n",
    "    - Internal groups create anonymous nodes; leaves are named tokens.\n",
    "    - ':len' attaches to the last emitted node or the just-closed group.\n",
    "    - Multiple top-level groups are unified under synthetic 'root0'.\n",
    "    \"\"\"\n",
    "    nodes: Dict[str, TNode] = {}\n",
    "    stack: List[Optional[str]] = []\n",
    "    last: Optional[str] = None\n",
    "    nid = 0\n",
    "\n",
    "    def new_id() -> str:\n",
    "        nonlocal nid\n",
    "        nid += 1\n",
    "        return f\"n{nid}\"\n",
    "\n",
    "    current_parent: Optional[str] = None\n",
    "    pending_name: Optional[str] = None\n",
    "    pending_len: Optional[float] = None\n",
    "\n",
    "    for tok in _tokenize(newick):\n",
    "        if tok == \"(\":\n",
    "            u = new_id()\n",
    "            nodes[u] = TNode(id=u)\n",
    "            if current_parent is not None:\n",
    "                nodes[current_parent].children.append(u)\n",
    "                nodes[u].parent = current_parent\n",
    "            stack.append(current_parent)\n",
    "            current_parent = u\n",
    "            last = None\n",
    "        elif tok == \",\":\n",
    "            last = None\n",
    "            pending_name = None\n",
    "            pending_len = None\n",
    "        elif tok == \")\":\n",
    "            if pending_name is not None:\n",
    "                nodes[current_parent].name = pending_name\n",
    "                pending_name = None\n",
    "            if pending_len is not None:\n",
    "                nodes[current_parent].blen = float(pending_len)\n",
    "                pending_len = None\n",
    "            current_parent = stack.pop()\n",
    "            last = None\n",
    "        elif tok == \";\":\n",
    "            break\n",
    "        elif tok.startswith(\":\"):\n",
    "            L = float(tok[1:].strip())\n",
    "            if last is None:\n",
    "                pending_len = L\n",
    "            else:\n",
    "                nodes[last].blen = L\n",
    "        else:\n",
    "            u = new_id()\n",
    "            nodes[u] = TNode(id=u, name=tok, parent=current_parent)\n",
    "            if current_parent is not None:\n",
    "                nodes[current_parent].children.append(u)\n",
    "            last = u\n",
    "            pending_name = None\n",
    "            pending_len = None\n",
    "\n",
    "    roots = [k for k, v in nodes.items() if v.parent is None]\n",
    "    if not roots:\n",
    "        raise ValueError(\"[Parse] No root detected.\")\n",
    "    if len(roots) == 1:\n",
    "        root_id = roots[0]\n",
    "    else:\n",
    "        root_id = \"root0\"\n",
    "        nodes[root_id] = TNode(id=root_id, name=\"root\", parent=None, blen=0.0, children=roots)\n",
    "        for r in roots:\n",
    "            nodes[r].parent = root_id\n",
    "\n",
    "    _log(f\"[Parse] nodes={len(nodes):,} leaves={sum(1 for v in nodes.values() if not v.children):,} root={root_id}\")\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6a09a",
   "metadata": {},
   "source": [
    "## Tree utilities\n",
    "\n",
    "We derive:\n",
    "- Root detection by `parent is None`\n",
    "- Leaf collection via DFS\n",
    "- Child ordering to avoid crossings by sorting children by their minimal leaf name\n",
    "- Cumulative branch length distances (X, later scaled)\n",
    "- Equal-spaced leaf Y, then postorder parent Y as mean of children\n",
    "\n",
    "All operations are linear in node count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50902638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree utilities — code\n",
    "from typing import Set\n",
    "\n",
    "\n",
    "def _collect_leaves(nodes: Dict[str, TNode], u: str) -> List[str]:\n",
    "    \"\"\"Return a list of leaf node ids under `u` (inclusive if `u` is a leaf).\"\"\"\n",
    "    if not nodes[u].children:\n",
    "        return [u]\n",
    "    acc: List[str] = []\n",
    "    for c in nodes[u].children:\n",
    "        acc.extend(_collect_leaves(nodes, c))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def _find_root(nodes: Dict[str, TNode]) -> str:\n",
    "    \"\"\"Return the single root id (node with `parent is None`).\"\"\"\n",
    "    for k, v in nodes.items():\n",
    "        if v.parent is None:\n",
    "            return k\n",
    "    raise ValueError(\"No root\")\n",
    "\n",
    "\n",
    "def _sort_children_for_no_crossing(nodes: Dict[str, TNode]) -> None:\n",
    "    \"\"\"Sort children of each internal node by the minimal leaf name to reduce crossings.\n",
    "    \n",
    "    Optimized: Single postorder pass to compute and cache min leaf names bottom-up.\n",
    "    \"\"\"\n",
    "    root = _find_root(nodes)\n",
    "    min_leaf_cache: Dict[str, str] = {}\n",
    "    \n",
    "    def compute_min_leaf_name(u: str) -> str:\n",
    "        \"\"\"Compute min leaf name, caching results for performance.\"\"\"\n",
    "        if u in min_leaf_cache:\n",
    "            return min_leaf_cache[u]\n",
    "        \n",
    "        # If leaf, return name or fallback to ID\n",
    "        if not nodes[u].children:\n",
    "            name = nodes[u].name or u\n",
    "            min_leaf_cache[u] = name\n",
    "            return name\n",
    "        \n",
    "        # For internal nodes, min is the minimum of children's min\n",
    "        child_mins = [compute_min_leaf_name(c) for c in nodes[u].children]\n",
    "        result = min(child_mins)\n",
    "        min_leaf_cache[u] = result\n",
    "        return result\n",
    "    \n",
    "    # Postorder traversal: compute cache, then sort\n",
    "    stack: List[str] = [root]\n",
    "    while stack:\n",
    "        u = stack.pop()\n",
    "        if u not in min_leaf_cache:  # Not yet visited\n",
    "            # If all children cached, compute this node's min\n",
    "            if all(c in min_leaf_cache for c in nodes[u].children):\n",
    "                compute_min_leaf_name(u)\n",
    "                # Sort children by cached values\n",
    "                if nodes[u].children:\n",
    "                    nodes[u].children.sort(key=lambda c: min_leaf_cache[c])\n",
    "                continue\n",
    "            # Push current node back, then push children\n",
    "            stack.append(u)\n",
    "            for c in nodes[u].children:\n",
    "                if c not in min_leaf_cache:\n",
    "                    stack.append(c)\n",
    "\n",
    "\n",
    "def compute_cumdist(nodes: Dict[str, TNode], root: Optional[str] = None) -> Dict[str, float]:\n",
    "    \"\"\"Compute cumulative branch length distance from `root` to each node.\"\"\"\n",
    "    if root is None:\n",
    "        root = _find_root(nodes)\n",
    "    dist: Dict[str, float] = {root: 0.0}\n",
    "    stack: List[str] = [root]\n",
    "    while stack:\n",
    "        u = stack.pop()\n",
    "        for c in nodes[u].children:\n",
    "            dist[c] = dist[u] + max(0.0, float(nodes[c].blen))\n",
    "            stack.append(c)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def assign_y_equal_leaf_spacing(nodes: Dict[str, TNode], leaf_step: float) -> Dict[str, float]:\n",
    "    \"\"\"Assign Y such that leaves are equally spaced by `leaf_step`, parents at child mean.\n",
    "    \n",
    "    Optimized: Single DFS pass that assigns leaf indices incrementally and computes parent Y on way back up.\n",
    "    \"\"\"\n",
    "    root = _find_root(nodes)\n",
    "    _sort_children_for_no_crossing(nodes)\n",
    "    \n",
    "    y: Dict[str, float] = {}\n",
    "    leaf_counter = 0\n",
    "    \n",
    "    def dfs_assign_y(u: str) -> None:\n",
    "        \"\"\"Recursively assign Y coordinates: leaves get indexed, parents get mean of children.\"\"\"\n",
    "        nonlocal leaf_counter\n",
    "        if not nodes[u].children:\n",
    "            # Leaf: assign next index\n",
    "            y[u] = leaf_counter * leaf_step\n",
    "            leaf_counter += 1\n",
    "        else:\n",
    "            # Internal: recursively process children, then compute mean\n",
    "            for c in nodes[u].children:\n",
    "                dfs_assign_y(c)\n",
    "            y[u] = sum(y[c] for c in nodes[u].children) / len(nodes[u].children)\n",
    "    \n",
    "    dfs_assign_y(root)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b39007",
   "metadata": {},
   "source": [
    "## Layout and display graph build\n",
    "\n",
    "We map tree metrics to a display graph:\n",
    "- Scale cumulative distances to pixels for X\n",
    "- Create a non-overlapping set of vertical stems by spreading (quantized keys)\n",
    "- Build orthogonal edges: parent→elbow→vertical→child\n",
    "- Cache bend nodes and links to avoid duplicates\n",
    "- Add aligned right-tip markers at a shared X\n",
    "\n",
    "Outputs are two DataFrames: `nodes_df` (points) and `links_df` (edges).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout — code\n",
    "from typing import Any, Set\n",
    "\n",
    "\n",
    "def build_display_graph(\n",
    "    nodes: Dict[str, TNode],\n",
    "    *,\n",
    "    leaf_step: float = LEAF_Y_STEP_PX,\n",
    "    parent_stub: float = PARENT_STUB_PX,\n",
    "    tip_pad: float = TIP_PAD_PX,\n",
    "    x_scale: float = X_SCALE_PX,\n",
    "    min_level_gap: float = MIN_STEM_GAP_PX,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Create node/link DataFrames for Cosmograph.\n",
    "\n",
    "    Stages: compute cumulative X (scaled), spread stems to avoid overlap, build orthogonal\n",
    "    edges with bend caching, and add right-aligned leaf markers.\n",
    "    \n",
    "    Optimized: Use arrays and lists instead of list-of-dicts for much faster construction.\n",
    "    \"\"\"\n",
    "    def logv(*a: object) -> None:\n",
    "        _log(\"[Layout]\", *a)\n",
    "\n",
    "    t0 = time.time()\n",
    "    root = _find_root(nodes)\n",
    "    dist = compute_cumdist(nodes, root)\n",
    "    y = assign_y_equal_leaf_spacing(nodes, leaf_step)\n",
    "    logv(f\"dist & y assignment: {time.time()-t0:.2f}s\")\n",
    "\n",
    "    # 1) scale X by branch length\n",
    "    dist_px: Dict[str, float] = {u: float(dist[u]) * float(x_scale) for u in nodes}\n",
    "\n",
    "    # 2) compute stems and spread horizontally so verticals don't overlap\n",
    "    raw_stems = sorted({dist_px[u] + parent_stub for u in nodes})\n",
    "    spread_stems: List[float] = []\n",
    "    last: Optional[float] = None\n",
    "    for sx in raw_stems:\n",
    "        spread = sx if last is None else max(sx, last + float(min_level_gap))\n",
    "        spread_stems.append(spread)\n",
    "        last = spread\n",
    "\n",
    "    def q(v: float) -> float:\n",
    "        return float(f\"{v:.6f}\")\n",
    "\n",
    "    stem_map: Dict[float, float] = {q(o): s for o, s in zip(raw_stems, spread_stems)}\n",
    "\n",
    "    def stem_x(u: str) -> float:\n",
    "        return stem_map[q(dist_px[u] + parent_stub)]\n",
    "\n",
    "    leaves = [k for k, v in nodes.items() if not v.children]\n",
    "\n",
    "    # Pre-allocate arrays/lists for performance\n",
    "    num_nodes = len(nodes)\n",
    "    max_links = num_nodes * 4  # Estimate: each node might add 2-3 links (tree + bends + markers)\n",
    "    \n",
    "    pts_id: List[int] = []\n",
    "    pts_x: List[float] = []\n",
    "    pts_y: List[float] = []\n",
    "    pts_size: List[float] = []\n",
    "    pts_color: List[str] = []\n",
    "    pts_label: List[str] = []\n",
    "    pts_kind: List[str] = []\n",
    "    \n",
    "    links_source: List[int] = []\n",
    "    links_target: List[int] = []\n",
    "    links_color: List[str] = []\n",
    "    \n",
    "    node_id_actual: Dict[str, int] = {}\n",
    "    pid_to_idx: Dict[int, int] = {}  # Reverse lookup for O(1) access\n",
    "    next_id = 0\n",
    "    point_cache: Dict[Tuple[float, float], int] = {}  # Only (x,y) for bend cache\n",
    "    link_cache: Set[Tuple[int, int]] = set()\n",
    "\n",
    "    def get_size_for_kind(kind: str) -> float:\n",
    "        if kind == \"leaf\":\n",
    "            return SIZE_LEAF_REAL\n",
    "        elif kind == \"leaf_marker\":\n",
    "            return SIZE_LEAF_MARKER\n",
    "        elif kind == \"internal\":\n",
    "            return SIZE_INTERNAL\n",
    "        elif kind == \"bend\":\n",
    "            return SIZE_BEND\n",
    "        else:\n",
    "            return 4.0\n",
    "    \n",
    "    def get_color_for_kind(kind: str) -> str:\n",
    "        if kind == \"leaf\" or kind == \"leaf_marker\":\n",
    "            return COLOR_LEAF\n",
    "        elif kind == \"internal\":\n",
    "            return COLOR_INTERNAL\n",
    "        elif kind == \"bend\":\n",
    "            return COLOR_BEND\n",
    "        else:\n",
    "            return COLOR_BEND\n",
    "\n",
    "    def add_point(kind: str, x: float, yv: float, *, label: str = \"\", \n",
    "                  color: Optional[str] = None, size: Optional[float] = None, \n",
    "                  cache_bend: bool = True) -> int:\n",
    "        nonlocal next_id\n",
    "        xq, yq = q(x), q(yv)\n",
    "        if cache_bend and kind == \"bend\":\n",
    "            key = (xq, yq)\n",
    "            if key in point_cache:\n",
    "                return point_cache[key]\n",
    "        \n",
    "        pid = next_id\n",
    "        next_id += 1\n",
    "\n",
    "        if size is None:\n",
    "            size = get_size_for_kind(kind)\n",
    "        if color is None:\n",
    "            color = get_color_for_kind(kind)\n",
    "\n",
    "        # Store reverse mapping for O(1) lookup\n",
    "        pid_to_idx[pid] = len(pts_id)\n",
    "        pts_id.append(pid)\n",
    "        pts_x.append(xq)\n",
    "        pts_y.append(yq)\n",
    "        pts_size.append(size)\n",
    "        pts_color.append(color)\n",
    "        pts_label.append(label)\n",
    "        pts_kind.append(kind)\n",
    "        \n",
    "        if cache_bend and kind == \"bend\":\n",
    "            point_cache[(xq, yq)] = pid\n",
    "        return pid\n",
    "\n",
    "    def add_link(s: int, t: int, *, color: Optional[str] = None) -> None:\n",
    "        key = (s, t)\n",
    "        if key in link_cache:\n",
    "            return\n",
    "        link_cache.add(key)\n",
    "        links_source.append(s)\n",
    "        links_target.append(t)\n",
    "        links_color.append(color or COLOR_LINK)\n",
    "\n",
    "    # 3) create real tree nodes at initial X\n",
    "    t1 = time.time()\n",
    "    for u, v in nodes.items():\n",
    "        kind = \"leaf\" if not v.children else \"internal\"\n",
    "        label = v.name if v.name else (u if kind == \"leaf\" else \"\")\n",
    "        ex = q(stem_x(u))  # elbow x\n",
    "        node_x_display = q(ex - float(PARENT_STUB_PX))\n",
    "        pid = add_point(kind, node_x_display, y[u], label=label, cache_bend=False)\n",
    "        node_id_actual[u] = pid\n",
    "    logv(f\"tree nodes creation: {time.time()-t1:.2f}s\")\n",
    "\n",
    "    # 4) orthogonal edges; move children to final weighted X\n",
    "    EPS = 1e-6\n",
    "    t2 = time.time()\n",
    "    for u, v in nodes.items():\n",
    "        ex = q(stem_x(u))\n",
    "        y_parent = y[u]\n",
    "        for c in v.children:\n",
    "            y_child = y[c]\n",
    "            true_len_px = max(0.0, float(nodes[c].blen)) * float(x_scale)\n",
    "            child_pid = node_id_actual[c]\n",
    "            \n",
    "            # Update x coordinate directly using O(1) lookup\n",
    "            child_idx = pid_to_idx[child_pid]\n",
    "            pts_x[child_idx] = q(ex + float(WEIGHTED_STUB_PX) + true_len_px)\n",
    "\n",
    "            elbow_top = add_point(\"bend\", ex, y_parent, cache_bend=True)\n",
    "            add_link(node_id_actual[u], elbow_top)\n",
    "            if abs(y_parent - y_child) > EPS:\n",
    "                elbow_bot = add_point(\"bend\", ex, y_child, cache_bend=True)\n",
    "                add_link(elbow_top, elbow_bot)\n",
    "                add_link(elbow_bot, child_pid)\n",
    "            else:\n",
    "                add_link(elbow_top, child_pid)\n",
    "    logv(f\"orthogonal edges: {time.time()-t2:.2f}s\")\n",
    "\n",
    "    # 5) aligned right guideline X and leaf markers\n",
    "    t3 = time.time()\n",
    "    max_leaf_x = 0.0\n",
    "    if leaves:\n",
    "        max_leaf_x = max(pts_x[pid_to_idx[node_id_actual[lf]]] for lf in leaves)\n",
    "    x_tipline = max_leaf_x + tip_pad\n",
    "    \n",
    "    for lf in leaves:\n",
    "        leaf_pid = node_id_actual[lf]\n",
    "        leaf_idx = pid_to_idx[leaf_pid]\n",
    "        leaf_y = pts_y[leaf_idx]\n",
    "        leaf_label = pts_label[leaf_idx]\n",
    "        \n",
    "        pid = add_point(\n",
    "            \"leaf_marker\", x_tipline, leaf_y, label=leaf_label, color=COLOR_LEAF,\n",
    "            size=SIZE_LEAF_MARKER, cache_bend=False,\n",
    "        )\n",
    "        add_link(pid, leaf_pid)\n",
    "    logv(f\"leaf markers: {time.time()-t3:.2f}s\")\n",
    "\n",
    "    # Build DataFrames from arrays - much faster\n",
    "    t4 = time.time()\n",
    "    nodes_df = pd.DataFrame({\n",
    "        \"id\": pts_id,\n",
    "        \"x\": pts_x,\n",
    "        \"y\": pts_y,\n",
    "        \"size\": pts_size,\n",
    "        \"color\": pts_color,\n",
    "        \"label\": pts_label,\n",
    "        \"kind\": pts_kind,\n",
    "    })\n",
    "    links_df = pd.DataFrame({\n",
    "        \"source\": links_source,\n",
    "        \"target\": links_target,\n",
    "        \"color\": links_color,\n",
    "    })\n",
    "    logv(f\"DataFrame creation: {time.time()-t4:.2f}s\")\n",
    "    logv(f\"total: {time.time()-t0:.2f}s nodes_df={nodes_df.shape} links_df={links_df.shape} (markers @ x={x_tipline:.1f})\")\n",
    "    return nodes_df, links_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71442ac0",
   "metadata": {},
   "source": [
    "## Rendering with Cosmograph\n",
    "\n",
    "We map DataFrame columns to Cosmograph fields and disable the physics simulation:\n",
    "- Coordinates are scaled (compact view), sizes are per-kind to emphasize leaves and markers\n",
    "- Labels are shown only when hovered or dynamically when space allows\n",
    "- Links are straight segments defined by source/target ids\n",
    "\n",
    "This preserves interactivity for very large trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d329b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering — code\n",
    "\n",
    "def render_cosmograph(nodes_df: pd.DataFrame, links_df: pd.DataFrame, *, link_px: float = LINK_WIDTH_PX):\n",
    "    \"\"\"Create a Cosmograph widget with scaled coordinates and per-kind sizes.\n",
    "    \n",
    "    Optimized: Reduce DataFrame copies, use vectorized operations.\n",
    "    \"\"\"\n",
    "    from cosmograph_widget import Cosmograph\n",
    "\n",
    "    for c in [\"id\", \"x\", \"y\", \"size\", \"color\", \"label\"]:\n",
    "        assert c in nodes_df.columns, f\"nodes missing {c}\"\n",
    "    for c in [\"source\", \"target\", \"color\"]:\n",
    "        assert c in links_df.columns, f\"links missing {c}\"\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Create mapping for size_by_kind - faster than apply()\n",
    "    kind_to_size = {\n",
    "        \"leaf_marker\": 24.0,\n",
    "        \"leaf\": 18.0,\n",
    "        \"internal\": 10.0,\n",
    "        \"bend\": 3.0,\n",
    "    }\n",
    "    default_size = 8.0\n",
    "\n",
    "    # Compact view scaling\n",
    "    scale_factor: float = 0.3\n",
    "    \n",
    "    # Build final DataFrame with all transformations in one go\n",
    "    t1 = time.time()\n",
    "    nodes_df_scaled = pd.DataFrame({\n",
    "        \"id\": nodes_df[\"id\"].astype(int),\n",
    "        \"x\": (nodes_df[\"x\"].astype(float) * scale_factor),\n",
    "        \"y\": (nodes_df[\"y\"].astype(float) * scale_factor),\n",
    "        \"pixel_size\": nodes_df[\"kind\"].map(lambda k: kind_to_size.get(k, default_size)).astype(float),\n",
    "        \"color\": nodes_df[\"color\"],\n",
    "        \"label\": nodes_df[\"label\"],\n",
    "    })\n",
    "    _log(f\"[Render] DataFrame prep: {time.time()-t1:.2f}s\")\n",
    "    \n",
    "    t2 = time.time()\n",
    "    links_df_prep = pd.DataFrame({\n",
    "        \"source\": links_df[\"source\"].astype(int),\n",
    "        \"target\": links_df[\"target\"].astype(int),\n",
    "        \"color\": links_df[\"color\"],\n",
    "    })\n",
    "    _log(f\"[Render] Links prep: {time.time()-t2:.2f}s\")\n",
    "    \n",
    "    t3 = time.time()\n",
    "    w = Cosmograph(\n",
    "        points=nodes_df_scaled,\n",
    "        links=links_df_prep,\n",
    "        point_id_by=\"id\",\n",
    "        point_x_by=\"x\",\n",
    "        point_y_by=\"y\",\n",
    "        point_color_by=\"color\",\n",
    "        point_size_by=\"pixel_size\",\n",
    "        point_label_by=\"label\",\n",
    "        link_source_by=\"source\",\n",
    "        link_target_by=\"target\",\n",
    "        link_color_by=\"color\",\n",
    "        link_width_by=None,\n",
    "        link_width=float(link_px) * 2,\n",
    "        disable_simulation=True,\n",
    "        fit_view_on_init=True,\n",
    "        fit_view_padding=0.06,\n",
    "        enable_drag=False,\n",
    "        show_hovered_point_label=True,\n",
    "        show_dynamic_labels=True,\n",
    "        show_legends=False,\n",
    "        scale_points_on_zoom=True,\n",
    "    )\n",
    "    _log(f\"[Render] Widget init: {time.time()-t3:.2f}s\")\n",
    "    _log(f\"[Render] Total: {time.time()-t0:.2f}s\")\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60001c57",
   "metadata": {},
   "source": [
    "## I/O and run\n",
    "\n",
    "We read a local Newick file path, take the first tree terminated by `;`, build the display graph, and render the widget. Adjust parameters if lines are cramped or too sparse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O and execution — code\n",
    "\n",
    "def read_newick_input(path_or_text: str) -> str:\n",
    "    \"\"\"Read from local file if path exists; otherwise treat input as literal Newick.\"\"\"\n",
    "    if os.path.exists(path_or_text):\n",
    "        with open(path_or_text, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            s = f.read()\n",
    "        _log(f\"[Input] Read file '{path_or_text}' len={len(s):,}\")\n",
    "        return s.strip()\n",
    "    _log(f\"[Input] Treating argument as literal Newick (len={len(path_or_text):,})\")\n",
    "    return path_or_text.strip()\n",
    "\n",
    "\n",
    "def run_all(\n",
    "    path_or_text: str,\n",
    "    *,\n",
    "    leaf_step: float = LEAF_Y_STEP_PX,\n",
    "    parent_stub: float = PARENT_STUB_PX,\n",
    "    tip_pad: float = TIP_PAD_PX,\n",
    "    x_scale: float = X_SCALE_PX,\n",
    "    min_level_gap: float = MIN_STEM_GAP_PX,\n",
    "):\n",
    "    \"\"\"End-to-end: parse Newick, build display graph, render cosmograph.\n",
    "\n",
    "    Returns widget and the two DataFrames for downstream inspection.\n",
    "    \"\"\"\n",
    "    newick = read_newick_input(path_or_text)\n",
    "    parts = [p.strip() for p in newick.split(\";\") if p.strip()]\n",
    "    if not parts:\n",
    "        raise ValueError(\"No Newick tree found.\")\n",
    "    tree_s = parts[0] + \";\"\n",
    "    _log(f\"[Run] Using first tree substring len={len(tree_s)}\")\n",
    "\n",
    "    nodes = parse_newick(tree_s)\n",
    "    nodes_df, links_df = build_display_graph(\n",
    "        nodes,\n",
    "        leaf_step=leaf_step,\n",
    "        parent_stub=parent_stub,\n",
    "        tip_pad=tip_pad,\n",
    "        x_scale=x_scale,\n",
    "        min_level_gap=min_level_gap,\n",
    "    )\n",
    "    _log(\"[Run] Rendering widget...\")\n",
    "    w = render_cosmograph(nodes_df, links_df)\n",
    "    return w, nodes_df, links_df\n",
    "\n",
    "\n",
    "# Local path and parameters\n",
    "NEWICK: str = \"/Users/gushchin_a/Downloads/UShER SARS-CoV-2 latest.nwk\"\n",
    "params = dict[str, float](\n",
    "    x_scale=140.0,\n",
    "    min_level_gap=56.0,\n",
    "    leaf_step=400.0,\n",
    "    parent_stub=20.0,\n",
    "    tip_pad=40.0,\n",
    ")\n",
    "\n",
    "w, nodes_df, links_df = run_all(NEWICK, **params)\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(w)\n",
    "except Exception:\n",
    "    print(\"Cosmograph widget created:\", w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
